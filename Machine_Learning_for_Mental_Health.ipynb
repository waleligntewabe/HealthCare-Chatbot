{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleligntewabe/HealthCare-Chatbot/blob/main/Machine_Learning_for_Mental_Health.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F311%2F673%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240128%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240128T094606Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D33b5dbfd6c8722ee6ba78dbb72b59c183c23084a010053be4fb491b3db2dfeae4080bf585fbb0c7e2946ba809a68c26d9d273a846de6d92d21035fb32db92aff937376d002130a5c83388dd386ef958adda7b236564ff5ad753cbdc41803307ba03ae673d3bb37be82118c0cebd54faa6e95a87ff384402aee6edd181e6b790e724b6519d482ccf90d7bd98b4625c8b0445df50eee318bc86956d8f280786188b32a3da0d63e61ce91010c37c36f8aba8b865c3d5ebda7ab3d4cc8f65c221bff64f26061faf8b2dd68b1f54b6327caf9b65e9ddc8bb3b158f2074eb6ccd3f020228530e70757135ab471c5b6b05de4782dbf5b7eeddd3f87f0d30142e5eb7e07'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "2ldgTEIHdlDg"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "_cell_guid": "b5d748ec-ba93-440b-9020-647f44fe6e0f",
        "_uuid": "aa2ef3305175ad6f2f289d18aa9d1e2e570bccd4",
        "collapsed": true,
        "id": "8w2gIDeCdlDk"
      },
      "cell_type": "markdown",
      "source": [
        "# **Predictors of mental health illness** <br>\n",
        "Kairos<br>\n",
        "Created: 1/23/2018<br>\n",
        "Last update: 6/23/2018<br>\n",
        "\n",
        "This kernel is modified from the “starter kernel” by Megan Risdal<br>\n",
        "\n",
        "### **Question:**\n",
        "**Can you predict whether a patient should be treated of his/her mental illness or not according to the values obtained in the dataset?**\n",
        "\n",
        "This is my first kernel after taking several courses of ML. I'm trying to understand better every concept by practicing and Kaggle is a good place to do it. Thanks Kaggle team.\n",
        "\n",
        "The proccess is the following:\n",
        "1. [Library and data loading](#Library_and_data_loading)\n",
        "2. [Data cleaning](#Data_cleaning)\n",
        "3. [Encoding data](#Encoding_data)\n",
        "4. [Covariance Matrix. Variability comparison between categories of variables](#Covariance_Matrix)\n",
        "5. [Some charts to see data relationship](#Some_charts_to_see_data_relationship)\n",
        "6. [Scaling and fitting](#Scaling_and_fitting)\n",
        "7. [Tuning](#Tuning)\n",
        "8. [Evaluating models](#Evaluating_models)    \n",
        "    1. [Logistic Eegression](#Logistic_regressio)\n",
        "    2. [KNeighbors Classifier](#KNeighborsClassifier)\n",
        "    3. [Decision Tree Classifier](#Decision_Tree_classifier)\n",
        "    4. [Random Forests](#Random_Forests)\n",
        "    5. [Bagging](#Bagging)\n",
        "    6. [Boosting](#Boosting)\n",
        "    7. [Stacking](#Stacking)\n",
        "9. [Predicting with Neural Network](#Predicting_with_Neural_Network)\n",
        "10. [Success method plot](#Success_method_plot)\n",
        "11. [Creating predictions on test set](#Creating_predictions_on_test_set)\n",
        "12. [Submission](#Submission)\n",
        "13. [Conclusions](#Conclusions)\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "dc7cd7b3-32e0-4284-b669-87d4fb6dbaf8",
        "_uuid": "dfeb8a6c8cc31996e69537a9a25102c42ccf3e6d",
        "id": "UqNbSAK6dlDn"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Library_and_data_loading'></a>\n",
        "## **1. Library and data loading** ##"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "507667c6-d01e-44e4-b8d7-a2d61d3eb02a",
        "_uuid": "d59a9a91a5da35354233aaf9fc1f0dd66686349b",
        "trusted": true,
        "collapsed": true,
        "id": "aGzVs89RdlDn"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import randint\n",
        "\n",
        "# prep\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
        "\n",
        "# models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "\n",
        "# Validation libraries\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Neural Network\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.grid_search import RandomizedSearchCV\n",
        "\n",
        "#Bagging\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Naive bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Stacking\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "#reading in CSV's from a file path\n",
        "train_df = pd.read_csv('../input/survey.csv')\n",
        "\n",
        "\n",
        "#Pandas: whats the data row count?\n",
        "print(train_df.shape)\n",
        "\n",
        "#Pandas: whats the distribution of the data?\n",
        "print(train_df.describe())\n",
        "\n",
        "#Pandas: What types of data do i have?\n",
        "print(train_df.info())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9a8c2272-ba6c-477a-9710-b82d57a1804f",
        "_uuid": "e4eef2cb6628af4e719fdbd434ccbacc1846e487",
        "id": "IlZLsLpDdlDo"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Data_cleaning'></a>\n",
        "## **2. Data cleaning** ##"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "a8e060e1-18fa-4214-a6fb-f924f74af108",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "6088e9b05d062fbed2c2272924e9d8aa0e23e5b7",
        "scrolled": false,
        "trusted": true,
        "collapsed": true,
        "id": "9jK4HHfadlDo"
      },
      "cell_type": "code",
      "source": [
        "#missing data\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)\n",
        "print(missing_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d21825da-92d6-48e2-9ab9-c63fbbbbd2b7",
        "_uuid": "50bdd9973655b16c61711d519645df6afb2ca214",
        "trusted": true,
        "collapsed": true,
        "id": "q_s5caEadlDp"
      },
      "cell_type": "code",
      "source": [
        "#dealing with missing data\n",
        "#Let’s get rid of the variables \"Timestamp\",“comments”, “state” just to make our lives easier.\n",
        "train_df = train_df.drop(['comments'], axis= 1)\n",
        "train_df = train_df.drop(['state'], axis= 1)\n",
        "train_df = train_df.drop(['Timestamp'], axis= 1)\n",
        "\n",
        "train_df.isnull().sum().max() #just checking that there's no missing data missing...\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "871f195e-d25d-426a-84f5-997b017b892c",
        "_uuid": "7a54d86c30dab2e270e7374455178f8abcc15a7c",
        "id": "83ZqfKPMdlDp"
      },
      "cell_type": "markdown",
      "source": [
        "**Cleaning NaN**"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "2bf70e26-afd9-4766-95ae-68d8ff9b21db",
        "_uuid": "08b863f7d666b7e68cef056ba2a0ae033cbdeb9d",
        "trusted": true,
        "collapsed": true,
        "id": "2mbmRvGJdlDq"
      },
      "cell_type": "code",
      "source": [
        "# Assign default values for each data type\n",
        "defaultInt = 0\n",
        "defaultString = 'NaN'\n",
        "defaultFloat = 0.0\n",
        "\n",
        "# Create lists by data tpe\n",
        "intFeatures = ['Age']\n",
        "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
        "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
        "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
        "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
        "                 'seek_help']\n",
        "floatFeatures = []\n",
        "\n",
        "# Clean the NaN's\n",
        "for feature in train_df:\n",
        "    if feature in intFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultInt)\n",
        "    elif feature in stringFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultString)\n",
        "    elif feature in floatFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultFloat)\n",
        "    else:\n",
        "        print('Error: Feature %s not recognized.' % feature)\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4ec04bf5-c88f-4839-a79b-2d3ad6962599",
        "_uuid": "4507b7c43c9663f90a9cf915dd73850e4e0f17ab",
        "trusted": true,
        "collapsed": true,
        "id": "h8AdRf3AdlDq"
      },
      "cell_type": "code",
      "source": [
        "#clean 'Gender'\n",
        "#Slower case all columm's elements\n",
        "gender = train_df['Gender'].str.lower()\n",
        "#print(gender)\n",
        "\n",
        "#Select unique elements\n",
        "gender = train_df['Gender'].unique()\n",
        "\n",
        "#Made gender groups\n",
        "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
        "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
        "\n",
        "for (row, col) in train_df.iterrows():\n",
        "\n",
        "    if str.lower(col.Gender) in male_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
        "\n",
        "    if str.lower(col.Gender) in female_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
        "\n",
        "#Get rid of bullshit\n",
        "stk_list = ['A little about you', 'p']\n",
        "train_df = train_df[~train_df['Gender'].isin(stk_list)]\n",
        "\n",
        "print(train_df['Gender'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0e211fa8-a69e-42c1-adda-375d82916db4",
        "_uuid": "818c6a88caf07379d5012f15919d6eb46ae6d98c",
        "collapsed": true,
        "trusted": true,
        "id": "G9cLIbxidlDr"
      },
      "cell_type": "code",
      "source": [
        "#complete missing age with mean\n",
        "train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\n",
        "\n",
        "# Fill with media() values < 18 and > 120\n",
        "s = pd.Series(train_df['Age'])\n",
        "s[s<18] = train_df['Age'].median()\n",
        "train_df['Age'] = s\n",
        "s = pd.Series(train_df['Age'])\n",
        "s[s>120] = train_df['Age'].median()\n",
        "train_df['Age'] = s\n",
        "\n",
        "#Ranges of Age\n",
        "train_df['age_range'] = pd.cut(train_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ffa02f53-30cd-4f7e-bcd9-f74b3c0826c4",
        "_uuid": "55b6621c02ca8d8603d815da74b15ad621b46629",
        "trusted": true,
        "collapsed": true,
        "id": "QZMIuQridlDr"
      },
      "cell_type": "code",
      "source": [
        "#There are only 0.014% of self employed so let's change NaN to NOT self_employed\n",
        "#Replace \"NaN\" string from defaultString\n",
        "train_df['self_employed'] = train_df['self_employed'].replace([defaultString], 'No')\n",
        "print(train_df['self_employed'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d910581d-4b92-4919-ab5a-85b018158745",
        "_uuid": "b934d97a22a46c36e107d2e0fdeb9f0ee74dc532",
        "trusted": true,
        "collapsed": true,
        "id": "KLCnnxxTdlDr"
      },
      "cell_type": "code",
      "source": [
        "#There are only 0.20% of self work_interfere so let's change NaN to \"Don't know\n",
        "#Replace \"NaN\" string from defaultString\n",
        "\n",
        "train_df['work_interfere'] = train_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
        "print(train_df['work_interfere'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b77019bf-b900-4c2b-9676-792860d89825",
        "_uuid": "01bdb3e74278bd61fdbdda9b1f9a3085c873999b",
        "id": "RdRsed_udlDr"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Encoding_data'></a>\n",
        "## **3. Encoding data**"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "05a6455e-187d-4db2-bb71-4fbf2ba6d967",
        "_uuid": "af23578fce1520cbe5fd970b13c7ddd71f442018",
        "trusted": true,
        "collapsed": true,
        "id": "yCtz6-bfdlDs"
      },
      "cell_type": "code",
      "source": [
        "#Encoding data\n",
        "labelDict = {}\n",
        "for feature in train_df:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(train_df[feature])\n",
        "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "    train_df[feature] = le.transform(train_df[feature])\n",
        "    # Get labels\n",
        "    labelKey = 'label_' + feature\n",
        "    labelValue = [*le_name_mapping]\n",
        "    labelDict[labelKey] =labelValue\n",
        "\n",
        "for key, value in labelDict.items():\n",
        "    print(key, value)\n",
        "\n",
        "#Get rid of 'Country'\n",
        "train_df = train_df.drop(['Country'], axis= 1)\n",
        "train_df.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "38b322d1-4aa6-468d-b370-cc93d43272c2",
        "_uuid": "f1cc9baff7c37cdad9014bccd875f0328b9c0d9b",
        "id": "bdoA1ZBJdlDs"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing there aren't any missing data"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "0031aa27-9d12-4cae-b59a-9897371789c0",
        "_uuid": "0958b0da3e0f1e2aa54914da431f47a773b8dec0",
        "trusted": true,
        "collapsed": true,
        "id": "WKAWfZz1dlDs"
      },
      "cell_type": "code",
      "source": [
        "#missing data\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)\n",
        "print(missing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "245bfde3-4bf8-4f4f-8cc6-9e1d95b632a7",
        "_uuid": "d9c414ad9ba5ed0ceb519beb410bccd8c12a117e",
        "id": "QLTElZsqdlDs"
      },
      "cell_type": "markdown",
      "source": [
        "Features Scaling\n",
        "We're going to scale age, because is extremely different from the othere ones."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b56ba09c-796d-4515-95fc-b36611cdb266",
        "_uuid": "75911eb1235de12aa6277ec8751d336f60ba9eb8",
        "id": "6Gy_rKGCdlDt"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Covariance_Matrix'></a>\n",
        "## **4. Covariance Matrix. Variability comparison between categories of variables**"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "fa764109-e028-4ca6-a167-281f8dcf1056",
        "_uuid": "db911626ce6498bac062d8dc7e01bfe670427fb4",
        "trusted": true,
        "collapsed": true,
        "id": "jAE70EUrdlDt"
      },
      "cell_type": "code",
      "source": [
        "#correlation matrix\n",
        "corrmat = train_df.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corrmat, vmax=.8, square=True);\n",
        "plt.show()\n",
        "\n",
        "#treatment correlation matrix\n",
        "k = 10 #number of variables for heatmap\n",
        "cols = corrmat.nlargest(k, 'treatment')['treatment'].index\n",
        "cm = np.corrcoef(train_df[cols].values.T)\n",
        "sns.set(font_scale=1.25)\n",
        "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f71d0c3d-8554-4478-b1d5-7aa461fcb7bb",
        "_uuid": "22adfaf19848e1103804bf8737cb5656fcac5388",
        "id": "_54M7OlOdlDt"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Some_charts_to_see_data_relationship'></a>\n",
        "## **5. Some charts to see data relationship**"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "2af9fb8b-79ac-4444-95b0-210c704afef9",
        "_uuid": "39488f9878f2ab937c4ce888eb82eba133fb175c",
        "id": "RwEvjpjhdlDt"
      },
      "cell_type": "markdown",
      "source": [
        "Distribiution and density by Age"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "89387b66-3a36-4b3f-98a4-254253452056",
        "_uuid": "e7288897925d3f340ba4c2e73d2ef61c6ca28c4f",
        "trusted": true,
        "collapsed": true,
        "id": "qBiOWUh8dlDu"
      },
      "cell_type": "code",
      "source": [
        "# Distribiution and density by Age\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(train_df[\"Age\"], bins=24)\n",
        "plt.title(\"Distribuition and density by Age\")\n",
        "plt.xlabel(\"Age\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a8880fbd-1545-48dd-a850-1ccc6214bcdc",
        "_uuid": "9c24e2674ba7fe8cfecc0b911e6773512b7099c5",
        "id": "TKofBD3wdlDu"
      },
      "cell_type": "markdown",
      "source": [
        "Separate by treatment"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b464a345-00b2-47a2-9d3e-c7074cfaf790",
        "_uuid": "2cc9d4abe3ca092a5bf9b7a9cd9f0b4d443c0471",
        "trusted": true,
        "collapsed": true,
        "id": "Mu7GYUCRdlDu"
      },
      "cell_type": "code",
      "source": [
        "# Separate by treatment or not\n",
        "\n",
        "g = sns.FacetGrid(train_df, col='treatment', size=5)\n",
        "g = g.map(sns.distplot, \"Age\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "20b446a7-fe87-478d-9328-de7ea7afea5b",
        "_uuid": "1bfd6affb0501138a98d4dbc9c70ad491b35962c",
        "id": "3uh9I0bMdlDu"
      },
      "cell_type": "markdown",
      "source": [
        "How many people has been treated?"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "81f1eb2a-c3ac-433d-a674-24aa6a33d287",
        "_uuid": "ac35d322a601a3ff9fdde64fa5e33b28dbdd10e5",
        "trusted": true,
        "collapsed": true,
        "id": "v1GEDlhZdlDv"
      },
      "cell_type": "code",
      "source": [
        "# Let see how many people has been treated\n",
        "plt.figure(figsize=(12,8))\n",
        "labels = labelDict['label_Gender']\n",
        "g = sns.countplot(x=\"treatment\", data=train_df)\n",
        "g.set_xticklabels(labels)\n",
        "\n",
        "plt.title('Total Distribuition by treated or not')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d7a9a45c-0df3-48a4-9ab2-e5aaae9abe7f",
        "_uuid": "a781bf88a14f5bb937ede09d81365f16bdcbbe3f",
        "id": "lqwGkNkpdlDv"
      },
      "cell_type": "markdown",
      "source": [
        "Draw a nested barplot to show probabilities for class and sex"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "210c02cf-9296-4373-8725-bd13b819a9e4",
        "_uuid": "2b931335e19a15bf897fa8a6eabcd26cb263503a",
        "scrolled": true,
        "trusted": true,
        "collapsed": true,
        "id": "F0hufJ5RdlDv"
      },
      "cell_type": "code",
      "source": [
        "o = labelDict['label_age_range']\n",
        "\n",
        "g = sns.factorplot(x=\"age_range\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\",  ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Age')\n",
        "# replace legend labels\n",
        "\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6517af95-3b02-4b50-b246-ea56f61f6113",
        "_uuid": "4ed2e62093d643cf105829ff2ae9a9917b110996",
        "id": "9Rx_UghgdlDv"
      },
      "cell_type": "markdown",
      "source": [
        "Barplot to show probabilities for family history"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b93d6150-b23a-4b71-8cf8-a10b811152a8",
        "_uuid": "605bf86a497f0b7989b57a3458088131f564e2a8",
        "trusted": true,
        "collapsed": true,
        "id": "WMqYAvwbdlDw"
      },
      "cell_type": "code",
      "source": [
        "o = labelDict['label_family_history']\n",
        "g = sns.factorplot(x=\"family_history\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Family History')\n",
        "\n",
        "# replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "beecc2fe-4cd8-489c-bc0e-bb5ad633931c",
        "_uuid": "7c7baa6c000ab81edb071071d45bac309f796d80",
        "id": "n339Y1EbdlDw"
      },
      "cell_type": "markdown",
      "source": [
        "Barplot to show probabilities for care options"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c77da62e-f71f-49fb-9c13-fe2fea3d474e",
        "_uuid": "bc61dc5b0c4c0a8204453524438006a84f6168d1",
        "trusted": true,
        "collapsed": true,
        "id": "yk5fmIEhdlDw"
      },
      "cell_type": "code",
      "source": [
        "o = labelDict['label_care_options']\n",
        "g = sns.factorplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Care options')\n",
        "\n",
        "# replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "56de0fc1-8ee1-41b8-868e-133db7635c64",
        "_uuid": "5f9e29712de3b44df01755c481b898a38e508f07",
        "id": "dwhb2DmSdlDw"
      },
      "cell_type": "markdown",
      "source": [
        "Barplot to show probabilities for benefits"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "4fab65ea-f3f5-4831-9f3f-7560fb908d3e",
        "_uuid": "25c2da49fd8c83fc2d42355c0e147f439c00a7c0",
        "trusted": true,
        "collapsed": true,
        "id": "2-RLO6jZdlDx"
      },
      "cell_type": "code",
      "source": [
        "o = labelDict['label_benefits']\n",
        "g = sns.factorplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Benefits')\n",
        "\n",
        "# replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bebe13ce-94d5-487c-88b8-7a634f361223",
        "_uuid": "9cfc643a94d39e2c06ed870c306deee6a9219b60",
        "id": "dG6jYtpWdlDx"
      },
      "cell_type": "markdown",
      "source": [
        "Barplot to show probabilities for work interfere"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "1606646f-0db7-41f9-b4bc-f8f2c982087c",
        "_uuid": "a7f3daeded334645d4cf5bd202e3116811159481",
        "trusted": true,
        "collapsed": true,
        "id": "ONmA0vOsdlDx"
      },
      "cell_type": "code",
      "source": [
        "o = labelDict['label_work_interfere']\n",
        "g = sns.factorplot(x=\"work_interfere\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Work interfere')\n",
        "\n",
        "# replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4ea1fe2d-e6bd-434f-807c-9936f17be784",
        "_uuid": "ebb8c1dc1fdd5dcfa5f9d1b05db3d23323b21adc",
        "id": "eSvD1dzcdlDx"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Scaling_and_fitting'></a>\n",
        "## **6. Scaling and fitting** ##\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "a95cf3ba-36d4-4df5-9797-2ccf1f018f5a",
        "_uuid": "5bdd6122fff56b5957a59210160269e7a32af869",
        "id": "1yF6zJttdlDx"
      },
      "cell_type": "markdown",
      "source": [
        "Features Scaling\n",
        "We're going to scale age, because is extremely different from the othere ones."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "6ae3cc24-d8cf-4ab2-915d-091007ff2457",
        "_uuid": "d8dcf5e62e990fb6747f5695cbce9919f5cdec4b",
        "trusted": true,
        "collapsed": true,
        "id": "w4bxo1D6dlD1"
      },
      "cell_type": "code",
      "source": [
        "# Scaling Age\n",
        "scaler = MinMaxScaler()\n",
        "train_df['Age'] = scaler.fit_transform(train_df[['Age']])\n",
        "train_df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "653ecfa5-8248-41e3-a470-655859fd33f8",
        "_uuid": "ce9cbb939ed0411f3280348e888e448a623a55c5",
        "id": "ulk9YqjpdlD2"
      },
      "cell_type": "markdown",
      "source": [
        "Spliltting the dataset"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "3687ae06-561c-4a0c-94a4-aad2275022ce",
        "_uuid": "6477bae9fc3654aef51e7048c0382c7888c9e36c",
        "collapsed": true,
        "trusted": true,
        "id": "pjulnGXidlD2"
      },
      "cell_type": "code",
      "source": [
        "# define X and y\n",
        "feature_cols = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']\n",
        "X = train_df[feature_cols]\n",
        "y = train_df.treatment\n",
        "\n",
        "# split X and y into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Create dictionaries for final graph\n",
        "# Use: methodDict['Stacking'] = accuracy_score\n",
        "methodDict = {}\n",
        "rmseDict = ()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b958ffcc-6625-421e-b5d0-57cdd753d32f",
        "_uuid": "5cbfa3c0808b550849fbe80158556775a4367b03",
        "trusted": true,
        "collapsed": true,
        "id": "kcPzkQDYdlD2"
      },
      "cell_type": "code",
      "source": [
        "# Build a forest and compute the feature importances\n",
        "forest = ExtraTreesClassifier(n_estimators=250,\n",
        "                              random_state=0)\n",
        "\n",
        "forest.fit(X, y)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "labels = []\n",
        "for f in range(X.shape[1]):\n",
        "    labels.append(feature_cols[f])\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), labels, rotation='vertical')\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b07c9bf0-3323-4cb3-9589-fe64b1fd854a",
        "_uuid": "a5a4b72ee4b193749ff0f59acb689c5900d98ec1",
        "id": "bujy4zjPdlD3"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Tuning'></a>\n",
        "## **7. Tuning**\n",
        "### **Evaluating a Classification Model.** <br>\n",
        "This function will evalue:<br>\n",
        "* **Classification accuracy: **percentage of correct predictions\n",
        "* **Null accuracy:** accuracy that could be achieved by always predicting the most frequent class\n",
        "* **Percentage of ones**<br>\n",
        "* **Percentage of zero**s<br>\n",
        "* **Confusion matrix: **Table that describes the performance of a classification model\n",
        "        True Positives (TP): we correctly predicted that they do have diabetes\n",
        "        True Negatives (TN): we correctly predicted that they don't have diabetes\n",
        "        False Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\")\n",
        "        Falsely predict positive\n",
        "        False Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\")\n",
        "        Falsely predict negative\n",
        "\n",
        "* **False Positive Rate**<br>\n",
        "* **Precision of Positive value**<br>\n",
        "* **AUC:** is the percentage of the ROC plot that is underneath the curve\n",
        "        .90-1 = excellent (A)\n",
        "        .80-.90 = good (B)\n",
        "        .70-.80 = fair (C)\n",
        "        .60-.70 = poor (D)\n",
        "        .50-.60 = fail (F)\n",
        "And some others values for tuning processes.\n",
        "More information:  [http://www.ritchieng.com/machine-learning-evaluate-classification-model/]:\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ae969199-93b6-4566-a677-69560ab1760f",
        "_uuid": "8f672b391aa354c77032b1f0c174a59aaa75cea9",
        "id": "vEZD_It1dlD3"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "_cell_guid": "0c78481e-0e93-4369-932f-d2b21f1dea0c",
        "_uuid": "dec481c2407ad73187e7b678fbdb9812f6a636a8",
        "collapsed": true,
        "trusted": true,
        "id": "jdFg7xaYdlD3"
      },
      "cell_type": "code",
      "source": [
        "def evalClassModel(model, y_test, y_pred_class, plot=False):\n",
        "    #Classification accuracy: percentage of correct predictions\n",
        "    # calculate accuracy\n",
        "    print('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "    #Null accuracy: accuracy that could be achieved by always predicting the most frequent class\n",
        "    # examine the class distribution of the testing set (using a Pandas Series method)\n",
        "    print('Null accuracy:\\n', y_test.value_counts())\n",
        "\n",
        "    # calculate the percentage of ones\n",
        "    print('Percentage of ones:', y_test.mean())\n",
        "\n",
        "    # calculate the percentage of zeros\n",
        "    print('Percentage of zeros:',1 - y_test.mean())\n",
        "\n",
        "    #Comparing the true and predicted response values\n",
        "    print('True:', y_test.values[0:25])\n",
        "    print('Pred:', y_pred_class[0:25])\n",
        "\n",
        "    #Conclusion:\n",
        "    #Classification accuracy is the easiest classification metric to understand\n",
        "    #But, it does not tell you the underlying distribution of response values\n",
        "    #And, it does not tell you what \"types\" of errors your classifier is making\n",
        "\n",
        "    #Confusion matrix\n",
        "    # save confusion matrix and slice into four pieces\n",
        "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
        "    #[row, column]\n",
        "    TP = confusion[1, 1]\n",
        "    TN = confusion[0, 0]\n",
        "    FP = confusion[0, 1]\n",
        "    FN = confusion[1, 0]\n",
        "\n",
        "    # visualize Confusion Matrix\n",
        "    sns.heatmap(confusion,annot=True,fmt=\"d\")\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    #Metrics computed from a confusion matrix\n",
        "    #Classification Accuracy: Overall, how often is the classifier correct?\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
        "    print('Classification Accuracy:', accuracy)\n",
        "\n",
        "    #Classification Error: Overall, how often is the classifier incorrect?\n",
        "    print('Classification Error:', 1 - metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "    #False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
        "    false_positive_rate = FP / float(TN + FP)\n",
        "    print('False Positive Rate:', false_positive_rate)\n",
        "\n",
        "    #Precision: When a positive value is predicted, how often is the prediction correct?\n",
        "    print('Precision:', metrics.precision_score(y_test, y_pred_class))\n",
        "\n",
        "\n",
        "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
        "    print('AUC Score:', metrics.roc_auc_score(y_test, y_pred_class))\n",
        "\n",
        "    # calculate cross-validated AUC\n",
        "    print('Cross-validated AUC:', cross_val_score(model, X, y, cv=10, scoring='roc_auc').mean())\n",
        "\n",
        "    ##########################################\n",
        "    #Adjusting the classification threshold\n",
        "    ##########################################\n",
        "    # print the first 10 predicted responses\n",
        "    # 1D array (vector) of binary values (0, 1)\n",
        "    print('First 10 predicted responses:\\n', model.predict(X_test)[0:10])\n",
        "\n",
        "    # print the first 10 predicted probabilities of class membership\n",
        "    print('First 10 predicted probabilities of class members:\\n', model.predict_proba(X_test)[0:10])\n",
        "\n",
        "    # print the first 10 predicted probabilities for class 1\n",
        "    model.predict_proba(X_test)[0:10, 1]\n",
        "\n",
        "    # store the predicted probabilities for class 1\n",
        "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    if plot == True:\n",
        "        # histogram of predicted probabilities\n",
        "        # adjust the font size\n",
        "        plt.rcParams['font.size'] = 12\n",
        "        # 8 bins\n",
        "        plt.hist(y_pred_prob, bins=8)\n",
        "\n",
        "        # x-axis limit from 0 to 1\n",
        "        plt.xlim(0,1)\n",
        "        plt.title('Histogram of predicted probabilities')\n",
        "        plt.xlabel('Predicted probability of treatment')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "\n",
        "    # predict treatment if the predicted probability is greater than 0.3\n",
        "    # it will return 1 for all values above 0.3 and 0 otherwise\n",
        "    # results are 2D so we slice out the first column\n",
        "    y_pred_prob = y_pred_prob.reshape(-1,1)\n",
        "    y_pred_class = binarize(y_pred_prob, 0.3)[0]\n",
        "\n",
        "    # print the first 10 predicted probabilities\n",
        "    print('First 10 predicted probabilities:\\n', y_pred_prob[0:10])\n",
        "\n",
        "    ##########################################\n",
        "    #ROC Curves and Area Under the Curve (AUC)\n",
        "    ##########################################\n",
        "\n",
        "    #Question: Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
        "    #Answer: Plot the ROC curve!\n",
        "\n",
        "\n",
        "    #AUC is the percentage of the ROC plot that is underneath the curve\n",
        "    #Higher value = better classifier\n",
        "    roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "\n",
        "\n",
        "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
        "    # we pass y_test and y_pred_prob\n",
        "    # we do not use y_pred_class, because it will give incorrect results without generating an error\n",
        "    # roc_curve returns 3 objects fpr, tpr, thresholds\n",
        "    # fpr: false positive rate\n",
        "    # tpr: true positive rate\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
        "    if plot == True:\n",
        "        plt.figure()\n",
        "\n",
        "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.0])\n",
        "        plt.rcParams['font.size'] = 12\n",
        "        plt.title('ROC curve for treatment classifier')\n",
        "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    # define a function that accepts a threshold and prints sensitivity and specificity\n",
        "    def evaluate_threshold(threshold):\n",
        "        #Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
        "        #Specificity: When the actual value is negative, how often is the prediction correct?print('Sensitivity for ' + str(threshold) + ' :', tpr[thresholds > threshold][-1])\n",
        "        print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])\n",
        "\n",
        "    # One way of setting threshold\n",
        "    predict_mine = np.where(y_pred_prob > 0.50, 1, 0)\n",
        "    confusion = metrics.confusion_matrix(y_test, predict_mine)\n",
        "    print(confusion)\n",
        "\n",
        "\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3e4552da-c5cc-45af-81ca-05a090922bb0",
        "_uuid": "4e5d57cfad5eee9dd3a34ed9da5fdccce8dc7c3a",
        "id": "DKggubNIdlD4"
      },
      "cell_type": "markdown",
      "source": [
        "### **Tuning with cross validation score**"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ff07e090-5af7-4a06-b553-c86a7a75cd64",
        "_uuid": "8ac94690bafb3277fec2d35bd196c317a33c9555",
        "collapsed": true,
        "trusted": true,
        "id": "i2X167IvdlD4"
      },
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# Tuning with cross validation score\n",
        "##########################################\n",
        "def tuningCV(knn):\n",
        "\n",
        "    # search for an optimal value of K for KNN\n",
        "    k_range = list(range(1, 31))\n",
        "    k_scores = []\n",
        "    for k in k_range:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
        "        k_scores.append(scores.mean())\n",
        "    print(k_scores)\n",
        "    # plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
        "    plt.plot(k_range, k_scores)\n",
        "    plt.xlabel('Value of K for KNN')\n",
        "    plt.ylabel('Cross-Validated Accuracy')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "55a2a701-b435-4143-bc7b-c56b4a24491f",
        "_uuid": "1cae2be4f65fc14d55eb1331110f69f016df2dbc",
        "id": "9FZx3bBtdlD4"
      },
      "cell_type": "markdown",
      "source": [
        "### **Tuning with GridSearchCV** ###"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "736e766c-b1c8-4d7e-b1b0-1bdab402ee4f",
        "_uuid": "3f64ad65f27cd4a92e5593ed6359245f34ba0e8e",
        "collapsed": true,
        "trusted": true,
        "id": "E9QEaZyodlD4"
      },
      "cell_type": "code",
      "source": [
        "def tuningGridSerach(knn):\n",
        "    #More efficient parameter tuning using GridSearchCV\n",
        "    # define the parameter values that should be searched\n",
        "    k_range = list(range(1, 31))\n",
        "    print(k_range)\n",
        "\n",
        "    # create a parameter grid: map the parameter names to the values that should be searched\n",
        "    param_grid = dict(n_neighbors=k_range)\n",
        "    print(param_grid)\n",
        "\n",
        "    # instantiate the grid\n",
        "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "    # fit the grid with data\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # view the complete results (list of named tuples)\n",
        "    grid.grid_scores_\n",
        "\n",
        "    # examine the first tuple\n",
        "    print(grid.grid_scores_[0].parameters)\n",
        "    print(grid.grid_scores_[0].cv_validation_scores)\n",
        "    print(grid.grid_scores_[0].mean_validation_score)\n",
        "\n",
        "    # create a list of the mean scores only\n",
        "    grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
        "    print(grid_mean_scores)\n",
        "\n",
        "    # plot the results\n",
        "    plt.plot(k_range, grid_mean_scores)\n",
        "    plt.xlabel('Value of K for KNN')\n",
        "    plt.ylabel('Cross-Validated Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    # examine the best model\n",
        "    print('GridSearch best score', grid.best_score_)\n",
        "    print('GridSearch best params', grid.best_params_)\n",
        "    print('GridSearch best estimator', grid.best_estimator_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9ff8088d-53b8-4724-ab5a-3c23e8728b61",
        "_uuid": "2ab0cb978d8869389d97fb4d29f4cab1c3a33ba7",
        "id": "OzsIGDzIdlD5"
      },
      "cell_type": "markdown",
      "source": [
        "### **Tuning with RandomizedSearchCV** ###"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "446bfe3e-b42f-4821-a20a-2cb07fd07c50",
        "_uuid": "b8d3212c33baad0e847e7a36272feb2ef31c4d5e",
        "collapsed": true,
        "trusted": true,
        "id": "vhGqDA6UdlD5"
      },
      "cell_type": "code",
      "source": [
        "def tuningRandomizedSearchCV(model, param_dist):\n",
        "    #Searching multiple parameters simultaneously\n",
        "    # n_iter controls the number of searches\n",
        "    rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
        "    rand.fit(X, y)\n",
        "    rand.grid_scores_\n",
        "\n",
        "    # examine the best model\n",
        "    print('Rand. Best Score: ', rand.best_score_)\n",
        "    print('Rand. Best Params: ', rand.best_params_)\n",
        "\n",
        "    # run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
        "    best_scores = []\n",
        "    for _ in range(20):\n",
        "        rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10)\n",
        "        rand.fit(X, y)\n",
        "        best_scores.append(round(rand.best_score_, 3))\n",
        "    print(best_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "70d61d3d-4b78-43cb-bccf-d7588dc61762",
        "_uuid": "695a98ccaa5870275bc2fe91ef9527dbb6833368",
        "id": "tkn_oswQdlD5"
      },
      "cell_type": "markdown",
      "source": [
        "### **Tuning with searching multiple parameters simultaneously** ###"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "114d4734-9647-4f09-b1bd-20c022421011",
        "_uuid": "0f4aad3e3f129aadfda0828345ce6418d46c5cf2",
        "collapsed": true,
        "trusted": true,
        "id": "j42aiHIYdlD5"
      },
      "cell_type": "code",
      "source": [
        "def tuningMultParam(knn):\n",
        "\n",
        "    #Searching multiple parameters simultaneously\n",
        "    # define the parameter values that should be searched\n",
        "    k_range = list(range(1, 31))\n",
        "    weight_options = ['uniform', 'distance']\n",
        "\n",
        "    # create a parameter grid: map the parameter names to the values that should be searched\n",
        "    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
        "    print(param_grid)\n",
        "\n",
        "    # instantiate and fit the grid\n",
        "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # view the complete results\n",
        "    print(grid.grid_scores_)\n",
        "\n",
        "    # examine the best model\n",
        "    print('Multiparam. Best Score: ', grid.best_score_)\n",
        "    print('Multiparam. Best Params: ', grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e05b3654a69f79cce46c2f5f007933de7dd91dc",
        "id": "vR3yZp8pdlD6"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Evaluating_models'></a>\n",
        "## **8. Evaluating models**<br><br>\n",
        "<a id='Logistic_regression'></a>\n",
        "### Logistic Regression"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "8613beea-11e3-426b-91f6-39df3626eaf9",
        "_uuid": "89f5e2c8ec51637568ac22982649205ca1c340e2",
        "collapsed": true,
        "trusted": true,
        "id": "NEHB_4FEdlD6"
      },
      "cell_type": "code",
      "source": [
        "def logisticRegression():\n",
        "    # train a logistic regression model on the training set\n",
        "    logreg = LogisticRegression()\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = logreg.predict(X_test)\n",
        "\n",
        "    print('########### Logistic Regression ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(logreg, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Log. Regres.'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "de99d1dd-eb98-478c-9ed0-3cb518eac4b2",
        "_uuid": "1f71d045fa89ece846fe9e44559f057293e8bdf7",
        "id": "2zhcuvRddlD6"
      },
      "cell_type": "markdown",
      "source": [
        "\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "2c090f3c-ecc9-433d-84a9-0d8f56cfd75d",
        "_uuid": "dd4c840a2b9a7ed7ad737730c4f780d11d603699",
        "trusted": true,
        "collapsed": true,
        "id": "lRdW4YLQdlD7"
      },
      "cell_type": "code",
      "source": [
        "logisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "74295e39-9b93-4601-8305-d1301e5fbd72",
        "_uuid": "8d69bf0ffde7e26e29b7bced3544432bf02ed86f",
        "id": "3Q7WSuu2dlD8"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='KNeighborsClassifier'></a>\n",
        "### KNeighbors Classifier"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c45537f3-72fa-47ff-a840-898e5bbed29d",
        "_uuid": "d5a089e0f01dce205366b7a99abbc3a6bb5568cc",
        "collapsed": true,
        "trusted": true,
        "id": "79ieKDowdlD8"
      },
      "cell_type": "code",
      "source": [
        "def Knn():\n",
        "    # Calculating the best parameters\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "    # From https://github.com/justmarkham/scikit-learn-videos/blob/master/08_grid_search.ipynb\n",
        "    #tuningCV(knn)\n",
        "    #tuningGridSerach(knn)\n",
        "    #tuningMultParam(knn)\n",
        "\n",
        "    # define the parameter values that should be searched\n",
        "    k_range = list(range(1, 31))\n",
        "    weight_options = ['uniform', 'distance']\n",
        "\n",
        "    # specify \"parameter distributions\" rather than a \"parameter grid\"\n",
        "    param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
        "    tuningRandomizedSearchCV(knn, param_dist)\n",
        "\n",
        "    # train a KNeighborsClassifier model on the training set\n",
        "    knn = KNeighborsClassifier(n_neighbors=27, weights='uniform')\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = knn.predict(X_test)\n",
        "\n",
        "    print('########### KNeighborsClassifier ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(knn, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['KNN'] = accuracy_score * 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "061c6d26-0e65-4f21-8995-f910526f5e8e",
        "_uuid": "ea3e9e3f9d300913aba08ef1027e70025b7b0102",
        "id": "fx3k3AthdlD9"
      },
      "cell_type": "markdown",
      "source": [
        "KNEIGHBORSCLASSIFIER"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c37a2ccc-f433-44a9-87d5-04e57e14f256",
        "_uuid": "604f548f0674bd6e66941cc967dfc07ce4e0701e",
        "scrolled": false,
        "trusted": true,
        "collapsed": true,
        "id": "FX0uNQkhdlD9"
      },
      "cell_type": "code",
      "source": [
        "Knn()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2138699d-4714-4e44-8121-d710a784b0f6",
        "_uuid": "6ca0e7311ac50b774f34803b1cb34fda2a7c106f",
        "id": "pYMylnYpdlD9"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Decision_Tree_classifier'></a>\n",
        "### Decision Tree classifier"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "fcb8d170-9cde-4660-81f4-a2c78a08a94d",
        "_uuid": "d3f64d71ce02ef0948f73771f94b345b1c738716",
        "collapsed": true,
        "trusted": true,
        "id": "6A_12TBfdlD9"
      },
      "cell_type": "code",
      "source": [
        "def treeClassifier():\n",
        "    # Calculating the best parameters\n",
        "    tree = DecisionTreeClassifier()\n",
        "    featuresSize = feature_cols.__len__()\n",
        "    param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, featuresSize),\n",
        "              \"min_samples_split\": randint(2, 9),\n",
        "              \"min_samples_leaf\": randint(1, 9),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "    tuningRandomizedSearchCV(tree, param_dist)\n",
        "\n",
        "    # train a decision tree model on the training set\n",
        "    tree = DecisionTreeClassifier(max_depth=3, min_samples_split=8, max_features=6, criterion='entropy', min_samples_leaf=7)\n",
        "    tree.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = tree.predict(X_test)\n",
        "\n",
        "    print('########### Tree classifier ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(tree, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Tree clas.'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f0005b0c-9f54-441d-b71d-6dc1eaf79a48",
        "_uuid": "b6f92441922c51ed520f54e588d28e5f6ac54d7c",
        "trusted": true,
        "collapsed": true,
        "id": "a-3O2nV1dlD9"
      },
      "cell_type": "code",
      "source": [
        "treeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "406048fd-2312-4975-bd64-3db6cfe85aa5",
        "_uuid": "5c0bc7e355c38fa87b250b6a56e002611c0ede1d",
        "id": "R3vzFrqpdlD-"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Random_Forests'></a>\n",
        "### Random Forests"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b5d831e8-3bcc-4e78-82bd-309a9a898954",
        "_uuid": "5419fdc8736774794575f2bd85a0f5341ad9d48d",
        "collapsed": true,
        "trusted": true,
        "id": "YSFj9yAhdlD-"
      },
      "cell_type": "code",
      "source": [
        "def randomForest():\n",
        "    # Calculating the best parameters\n",
        "    forest = RandomForestClassifier(n_estimators = 20)\n",
        "\n",
        "    featuresSize = feature_cols.__len__()\n",
        "    param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, featuresSize),\n",
        "              \"min_samples_split\": randint(2, 9),\n",
        "              \"min_samples_leaf\": randint(1, 9),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "    tuningRandomizedSearchCV(forest, param_dist)\n",
        "\n",
        "    # Building and fitting my_forest\n",
        "    forest = RandomForestClassifier(max_depth = None, min_samples_leaf=8, min_samples_split=2, n_estimators = 20, random_state = 1)\n",
        "    my_forest = forest.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = my_forest.predict(X_test)\n",
        "\n",
        "    print('########### Random Forests ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(my_forest, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['R. Forest'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d2b956e0-e921-4433-8cf1-3c4db0e26c12",
        "_uuid": "1c522cc7c4e6ba720b10620eb49f48274b24d79d",
        "trusted": true,
        "collapsed": true,
        "id": "RUqyq7_ydlD-"
      },
      "cell_type": "code",
      "source": [
        "randomForest()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1c07c4f6-5897-4bf5-9f3a-2706430d2e2f",
        "_uuid": "278639308461647ea1206a6d93efad39d699a8de",
        "id": "R54L5g2DdlD-"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Bagging'></a>\n",
        "### Bagging"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "1782b0bb-eb0a-4741-b4f4-b2c9900970b2",
        "_uuid": "50d47d51bb91989b421803dd5bb1b95022dd7c42",
        "collapsed": true,
        "trusted": true,
        "id": "S7DVJUFEdlD-"
      },
      "cell_type": "code",
      "source": [
        "def bagging():\n",
        "    # Building and fitting\n",
        "    bag = BaggingClassifier(DecisionTreeClassifier(), max_samples=1.0, max_features=1.0, bootstrap_features=False)\n",
        "    bag.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = bag.predict(X_test)\n",
        "\n",
        "    print('########### Bagging ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(bag, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Bagging'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "de06cee0-9024-4a22-80e3-f6cd9c8aee0a",
        "_uuid": "4fcc753e51ab46cf492ed7202d23bfcfac1c608a",
        "trusted": true,
        "collapsed": true,
        "id": "0hkJxZvVdlD_"
      },
      "cell_type": "code",
      "source": [
        "bagging()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8611c537-e9c9-4412-b513-8b0cf441ed05",
        "_uuid": "f99aa0dab6830aa2857d6003eef19ca2fbd754aa",
        "id": "g-sLuAffdlD_"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Boosting'></a>\n",
        "### Boosting"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b23c5f32-f61d-4391-a3b8-8a989bc8ce54",
        "_uuid": "6a7d03cd950cf99d5f6ea5d7bad0dceed2508a49",
        "collapsed": true,
        "trusted": true,
        "id": "tXauusaDdlD_"
      },
      "cell_type": "code",
      "source": [
        "def boosting():\n",
        "    # Building and fitting\n",
        "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "    boost = AdaBoostClassifier(base_estimator=clf, n_estimators=500)\n",
        "    boost.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = boost.predict(X_test)\n",
        "\n",
        "    print('########### Boosting ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(boost, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Boosting'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4415545b-a6ef-40cd-8583-ecb036b82db3",
        "_uuid": "7c2ee5da9f1d4708b6a73071c538760964188d97",
        "trusted": true,
        "collapsed": true,
        "id": "yxshkQZPdlD_"
      },
      "cell_type": "code",
      "source": [
        "boosting()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "615c515b-b3f3-4178-a5da-6ce2582b8d23",
        "_uuid": "7b2789cfb8a1b1afc4426883f2664016db3aaf61",
        "id": "8koNQc5udlEA"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Stacking'></a>\n",
        "### Stacking"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "a763ed38-22a7-4b50-bee4-db11b9bf6575",
        "_uuid": "cf645152f925cd1d5c0c79f3b46e7006ff6bbc92",
        "collapsed": true,
        "trusted": true,
        "id": "nRxbhVCNdlEA"
      },
      "cell_type": "code",
      "source": [
        "def stacking():\n",
        "    # Building and fitting\n",
        "    clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "    clf2 = RandomForestClassifier(random_state=1)\n",
        "    clf3 = GaussianNB()\n",
        "    lr = LogisticRegression()\n",
        "    stack = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)\n",
        "    stack.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = stack.predict(X_test)\n",
        "\n",
        "    print('########### Stacking ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(stack, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Stacking'] = accuracy_score * 100\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "37b8048f-a189-48f4-b855-4099debae483",
        "_uuid": "49178159638a6c10b86342dccc110656a70c9670",
        "trusted": true,
        "collapsed": true,
        "id": "IMl8692FdlEA"
      },
      "cell_type": "code",
      "source": [
        "stacking()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "87e8181f247c4dd00dd8b2caf65ebe5b76367719",
        "id": "El7Da9ymdlEA"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Predicting_with_Neural_Network'></a>\n",
        "## **9. Predicting with Neural Network**\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "ee05c058a7e73956696bead61f457ee04f39a004",
        "id": "F3whCQxLdlEA"
      },
      "cell_type": "markdown",
      "source": [
        "### Create input functions\n",
        "You must create input functions to supply data for training, evaluating, and prediction."
      ]
    },
    {
      "metadata": {
        "_uuid": "3c532804f31ae661e5cf820406e4eee58679dcc6",
        "collapsed": true,
        "trusted": true,
        "id": "_ANcw7BndlEB"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import argparse\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "train_steps = 1000\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "def train_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    return dataset.shuffle(1000).repeat().batch(batch_size)\n",
        "\n",
        "def eval_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
        "    features=dict(features)\n",
        "    if labels is None:\n",
        "        # No labels, use only features.\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    # Batch the examples\n",
        "    assert batch_size is not None, \"batch_size must not be None\"\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7540da5ccf242c31fae61193422a50c4132fb7cd",
        "id": "91BBFhwqdlEB"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the feature columns\n",
        "A feature column is an object describing how the model should use raw input data from the features dictionary. When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use."
      ]
    },
    {
      "metadata": {
        "_uuid": "4b51ea10c5fc254910a46910db0fb76b27150b24",
        "collapsed": true,
        "trusted": true,
        "id": "29XxkcwZdlEB"
      },
      "cell_type": "code",
      "source": [
        "# Define Tensorflow feature columns\n",
        "age = tf.feature_column.numeric_column(\"Age\")\n",
        "gender = tf.feature_column.numeric_column(\"Gender\")\n",
        "family_history = tf.feature_column.numeric_column(\"family_history\")\n",
        "benefits = tf.feature_column.numeric_column(\"benefits\")\n",
        "care_options = tf.feature_column.numeric_column(\"care_options\")\n",
        "anonymity = tf.feature_column.numeric_column(\"anonymity\")\n",
        "leave = tf.feature_column.numeric_column(\"leave\")\n",
        "work_interfere = tf.feature_column.numeric_column(\"work_interfere\")\n",
        "feature_columns = [age, gender, family_history, benefits, care_options, anonymity, leave, work_interfere]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ec5458a421476ca5b77b77d67e5d7dbd406090f",
        "id": "vZDzS1WZdlEB"
      },
      "cell_type": "markdown",
      "source": [
        "### Instantiate an Estimator\n",
        "Our problem is a classic classification problem. We want to predict whether a patient has to be treated or not. We'll use tf.estimator.DNNClassifier for deep models that perform multi-class classification."
      ]
    },
    {
      "metadata": {
        "_uuid": "605d76f9ecf1e3a87332633a0b84c68b04024494",
        "collapsed": true,
        "trusted": true,
        "id": "9tFMIEUOdlEC"
      },
      "cell_type": "code",
      "source": [
        "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
        "model = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
        "                                    hidden_units=[10, 10],\n",
        "                                    optimizer=tf.train.ProximalAdagradOptimizer(\n",
        "                                      learning_rate=0.1,\n",
        "                                      l1_regularization_strength=0.001\n",
        "                                    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "294ab3369fd6ddee67b62b402ebe707001010466",
        "id": "cSTcOlotdlEC"
      },
      "cell_type": "markdown",
      "source": [
        "### Train, Evaluate, and Predict\n",
        "Now that we have an Estimator object, we can call methods to do the following:\n",
        "\n",
        "* Train the model.\n",
        "* Evaluate the trained model.\n",
        "* Use the trained model to make predictions.\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "4fcb1a081143098bce426cc496167f024c432350",
        "id": "pu1FFlg4dlEC"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train the model\n",
        "The steps argument tells the method to stop training after a number of training steps."
      ]
    },
    {
      "metadata": {
        "_uuid": "805f28d819c59eee02123b11eff66d812d392188",
        "trusted": true,
        "collapsed": true,
        "id": "jpTPES6rdlED"
      },
      "cell_type": "code",
      "source": [
        "model.train(input_fn=lambda:train_input_fn(X_train, y_train, batch_size), steps=train_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a4e82a5b76e6d0a89d21187413ed1574788fbe5a",
        "id": "-I-C-6A4dlED"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the trained model\n",
        "Now that the model has been trained, we can get some statistics on its performance. The following code block evaluates the accuracy of the trained model on the test data."
      ]
    },
    {
      "metadata": {
        "_uuid": "2b99faa167137ef3e90c7ebb9cd093837e8d4ef5",
        "trusted": true,
        "collapsed": true,
        "id": "FTR4noGAdlEE"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the model.\n",
        "eval_result = model.evaluate(\n",
        "    input_fn=lambda:eval_input_fn(X_test, y_test, batch_size))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.2f}\\n'.format(**eval_result))\n",
        "\n",
        "#Data for final graph\n",
        "accuracy = eval_result['accuracy'] * 100\n",
        "methodDict['NN DNNClasif.'] = accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "de375081922a83052d997ce836c31884ce44efd7",
        "id": "_Rg3w8UDdlEE"
      },
      "cell_type": "markdown",
      "source": [
        "### Making predictions (inferring) from the trained model\n",
        "We now have a trained model that produces good evaluation results. We can now use the trained model to predict whether a patient needs treatment or not."
      ]
    },
    {
      "metadata": {
        "_uuid": "a72f2f39e610a12fea7f542fa4cccec9ca17544a",
        "collapsed": true,
        "trusted": true,
        "id": "J0-klEt1dlEF"
      },
      "cell_type": "code",
      "source": [
        "predictions = list(model.predict(input_fn=lambda:eval_input_fn(X_train, y_train, batch_size=batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e078018202e2a75c3cace605d815be5435798682",
        "scrolled": false,
        "trusted": true,
        "collapsed": true,
        "id": "u5Wpm_YKdlEF"
      },
      "cell_type": "code",
      "source": [
        "# Generate predictions from the model\n",
        "template = ('\\nIndex: \"{}\", Prediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "\n",
        "# Dictionary for predictions\n",
        "col1 = []\n",
        "col2 = []\n",
        "col3 = []\n",
        "\n",
        "\n",
        "for idx, input, p in zip(X_train.index, y_train, predictions):\n",
        "    v  = p[\"class_ids\"][0]\n",
        "    class_id = p['class_ids'][0]\n",
        "    probability = p['probabilities'][class_id] # Probability\n",
        "\n",
        "    # Adding to dataframe\n",
        "    col1.append(idx) # Index\n",
        "    col2.append(v) # Prediction\n",
        "    col3.append(input) # Expecter\n",
        "\n",
        "\n",
        "    #print(template.format(idx, v, 100 * probability, input))\n",
        "\n",
        "\n",
        "results = pd.DataFrame({'index':col1, 'prediction':col2, 'expected':col3})\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "83d68dc1-1929-4069-8b9f-2b1b0768840d",
        "_uuid": "289d8b5896d20f5859307e07c509c92151b4e942",
        "id": "g93mjFdrdlEG"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Success_method_plot'></a>\n",
        "## **10. Success method plot**"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ff9279ed-3a53-47ef-8d69-b9c013c73ba0",
        "_uuid": "67df920b185fcf2a8941369bb91c8975d0c8ce10",
        "collapsed": true,
        "trusted": true,
        "id": "UFuKS_CCdlEG"
      },
      "cell_type": "code",
      "source": [
        "def plotSuccess():\n",
        "    s = pd.Series(methodDict)\n",
        "    s = s.sort_values(ascending=False)\n",
        "    plt.figure(figsize=(12,8))\n",
        "    #Colors\n",
        "    ax = s.plot(kind='bar')\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
        "    plt.ylim([70.0, 90.0])\n",
        "    plt.xlabel('Method')\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.title('Success of methods')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3672320b-e060-45e4-b481-029ad98feb58",
        "_uuid": "26d24346015d93adf6c4fa9d384f480b7b391584",
        "scrolled": false,
        "trusted": true,
        "collapsed": true,
        "id": "6aw2EMEudlEG"
      },
      "cell_type": "code",
      "source": [
        "plotSuccess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "05e05c13-6e1f-4900-b147-844cf49cdb41",
        "_uuid": "97b824045c3668ad8eab81bdfe35d07ab0d18c76",
        "id": "snmNn8_0dlEG"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Creating_predictions_on_test_set'></a>\n",
        "## **11. Creating predictions on test set**"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "cd416a0e-a234-45c1-a502-e46d7b381dcd",
        "_uuid": "ddf3291a57a8ed1ebd10c81779abc44ff9f5ce72",
        "collapsed": true,
        "trusted": true,
        "id": "sDZjDMT6dlEG"
      },
      "cell_type": "code",
      "source": [
        "# Generate predictions with the best method\n",
        "clf = AdaBoostClassifier()\n",
        "clf.fit(X, y)\n",
        "dfTestPredictions = clf.predict(X_test)\n",
        "\n",
        "# Write predictions to csv file\n",
        "# We don't have any significative field so we save the index\n",
        "results = pd.DataFrame({'Index': X_test.index, 'Treatment': dfTestPredictions})\n",
        "# Save to file\n",
        "# This file will be visible after publishing in the output section\n",
        "results.to_csv('results.csv', index=False)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "35d306ec4cb719e14f1b2600dff7a3ffa89f1b47",
        "id": "Sa2asyICdlEH"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Submision'></a>\n",
        "## ** 12. Submision**"
      ]
    },
    {
      "metadata": {
        "_uuid": "8fdd6b0a10dd1efb08cfac45026ad83d3fd770eb",
        "id": "tYjRQN9PdlEH"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare Submission File\n",
        "We make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for our data is the index). The prediction column will use the name of the target field.\n",
        "\n",
        "We will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "224fe370c6c43359faa76d067a3ef39ed3b13402",
        "collapsed": true,
        "id": "6RFNTMvYdlEH"
      },
      "cell_type": "code",
      "source": [
        "# Write predictions to csv file\n",
        "# We don't have any significative field so we save the index\n",
        "results = pd.DataFrame({'Index': X_test.index, 'Treatment': dfTestPredictions})\n",
        "# Save to file\n",
        "# This file will be visible after publishing in the output section\n",
        "results.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e56961d7c4f00c35537023aad9c6cbf09cd8286a",
        "id": "6IdJteGOdlEH"
      },
      "cell_type": "markdown",
      "source": [
        "### Make Submission\n",
        "Hit the blue Publish button at the top of your notebook screen. It will take some time for your kernel to run. When it has finished your navigation bar at the top of the screen will have a tab for Output. This only shows up if you have written an output file (like we did in the Prepare Submission File step)."
      ]
    },
    {
      "metadata": {
        "_uuid": "14436d0791aad480e08b4d5dce1ca51c1a25bd3b",
        "id": "nD7y1M2qdlEH"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "_cell_guid": "2c05dd56-2528-40b1-9cd0-368300adc2c3",
        "_uuid": "d5972622da305ae627019fc0476a769a22a9f3fc",
        "collapsed": true,
        "id": "ZuTs9ZRZdlEH"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='Conclusions'></a>\n",
        "## **13. Conclusions**\n",
        "\n",
        "As a beginner I don't know whether the results are the best. I think over 80% of success in the majority of methods is a good rate, given the point is to know whether a patient needs treatment or not.\n",
        "\n",
        "There's only left to have a way to persist the model for future use without having to retrain. This job will be done in another kernel.\n",
        "\n",
        "\n",
        "Thanks for reading and if you'd like my job or want to give some advice, feel free.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "Machine Learning for Mental Health",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}